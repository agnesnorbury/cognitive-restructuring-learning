---
title: "modComp study: model-based analysis of causal attribution task data by learning condition"
output:
  html_document:
    html-math-method:
      method: mathjax
  #  pdf_document:
  # extra_dependencies: ["bbm"]
  # fig_caption: yes
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo=FALSE, error=TRUE, warning=FALSE, message=FALSE, fig.align='center')

# load packages
packages <- c("rstan", "dplyr", "tidyr", "bayesplot", "loo", "hBayesDM", "tidybayes", "forcats",
              "ggpmisc", "patchwork", "devtools", "reshape2", "ggExtra", "unikn", "svglite",
              "lme4", "glmnet", "ggcorrplot", "subscore", "boot")
if (length(setdiff(packages, rownames(installed.packages()))) > 0 ) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, require, character.only=TRUE)

# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# set task version 
task_ver <- "causal-attr-learn"

# # create figures subdir
# subdir <- "figures"
# if (!file.exists(subdir)){
#   dir.create(file.path(dirname(rstudioapi::getActiveDocumentContext()$path), subdir))
# }
```

```{r setup_rstan}
rstan_options(auto_write = TRUE)   # write the models so we don't have to recompile each time
nCores <- parallel::detectCores()    # get number of cores available for parallelisation
```

```{r setup_colour_scales}
# lets set some custom colour scales for our plots using unikn
# seecol(pal_unikn_pair)
palette2 <- usecol(pal_unikn_pair) 
# colours by intervention group
colours3 <- c("1" = palette2[2],      # restructuring + learning training
              "2" = palette2[3],      # control + learning training
              "3" = palette2[10]      # restructuring + learning control
              )
# colours by model parameter type
colours2 <- c("group mean" = palette2[14],
              "intervention effect" = palette2[2],  # cognitive restructuring vs control intervention
              "learning effect" = palette2[9]       # learning task vs control learning task
              )
```

```{r load_data}
# load long format data
data_long_all <- read.csv(file=paste0(task_ver, "-causal-attribution-task-data-anon.csv")) %>%
  dplyr::select(-X) %>%
  arrange(uid, taskNo, itemNo) %>%
  mutate(sess = taskNo + 1)

## get number of time points etc
nPpts <- length(unique(data_long_all$uid))
nTimes <- max(data_long_all$sess)
uids <- data_long_all %>%
  group_by(uid) %>%
  summarize() %>%
  mutate(ID=seq(1, nPpts, 1))   # add sequential numeric IDs for compatibility with rstan output    
data_long_all <- merge(data_long_all, uids, by="uid") %>%
  mutate(neg_pos=ifelse(valence=="positive",1,0)) %>%
  rename("ID" = ID.y)

nTrials_all <- data_long_all %>%
  group_by(uid, sess) %>%
  summarize(nTrials = n())
nTrials_max <- nTrials_all %>%
  {max(.$nTrials)}

# get lists of participants IDs by condition for use with other data
control_subs <- data_long_all %>%
  filter(interventionCondition=="control") %>%
  dplyr::select(uid, ID)
controls <- as.list(unique(control_subs$uid))
control_IDs <- as.list(unique(control_subs$ID))

learn_control_subs <- data_long_all %>%
  filter(learningCondition=="control") %>%
  dplyr::select(uid, ID)
learn_controls <- as.list(unique(learn_control_subs$uid))
learn_control_IDs <- as.list(unique(learn_control_subs$ID))

# get ordered list of intervention conditions
int_conds <- data_long_all %>%
  arrange(ID) %>%
  group_by(ID) %>%
  dplyr::select(ID, interventionCondition) %>%
  distinct() %>%
  mutate(condition01 = ifelse(interventionCondition=="psychoed", 1, 0))

learn_conds <- data_long_all %>%
  arrange(ID) %>%
  group_by(ID) %>%
  dplyr::select(ID, learningCondition) %>%
  distinct() %>%
  mutate(condition01 = ifelse(learningCondition=="causal", 1, 0))

# get lists of participants by study arm
s1 <- data_long_all %>%
  filter(interventionCondition=="psychoed" & learningCondition=="causal" ) %>%
  dplyr::select(ID)
subs_1 <- as.list(unique(s1$ID))

s2 <- data_long_all %>%
  filter(interventionCondition=="control" & learningCondition=="causal") %>%
  dplyr::select(ID)
subs_2 <- as.list(unique(s2$ID))

s3 <- data_long_all %>%
  filter(interventionCondition=="psychoed" & learningCondition=="control") %>%
  dplyr::select(ID)
subs_3 <- as.list(unique(s3$ID))
```

### Via generative model (both sessions data)

Latent traits of tendency to endorse an internal and global cause are modelled separately (bernoulli function with single parameter theta governing probability of endorsement on each trial)

Since estimates of theta were previously observed to be more precise when separate values were allowed for positive and negative events, we again allow different parameters for different valences.

Values of theta for each session were modelled separately but were assumed to be drawn from a multivariate normal distribution, i.e., were allowed to covary across sessions (uniform prior ranging -1 to 1), allowing direct estimation of correlation of estimates between sessions (as per [Rouder et al., 2019](https://doi.org/10.3758/s13423-018-1558-y) and [Haines et al., (2020)](https://psyarxiv.com/xr7y3/)).

Here, we can fit two different models - one which is agnostic to learning task condition, and one which accounts for potential effects of learning task condition on time 2 attribution tendencies


```{r stan_int_models_IG}
## specify model
# 1. model without learning conditions
# model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_additive"
# 2. model with learning conditions
model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_learning_additive"

## create arrays of choice options and responses for each participant and time point
internalChosen_neg <- internalChosen_pos <- globalChosen_neg <- globalChosen_pos <- array(0, dim = c(nPpts, nTimes, nTrials_max/2))
nT_ppts <- array(nTrials_max, dim = c(nPpts, nTimes))
for (i in 1:nPpts) {
  for (t in 1:nTimes) {
  internalChosen_neg[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==0])
  internalChosen_pos[i,t,] <- with(data_long_all, internalChosen[ID==i & sess==t & neg_pos==1])
  globalChosen_neg[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==0])
  globalChosen_pos[i,t,] <- with(data_long_all, globalChosen[ID==i & sess==t & neg_pos==1])
  }
}
## create list to pass to stan
data_list = list(
  nTimes = nTimes,
  nPpts = nPpts,
  nTrials_max = nTrials_max/2,             # max number of trials per  session per participant
  nT_ppts = nT_ppts,                       # actual number of trials per session per participant
  condition = int_conds$condition01,      # 0 = control, 1 = psychoed
  int_condition = int_conds$condition01,   # 0 = control, 1 = psychoed
  learn_condition = learn_conds$condition01,   # 0 = control, 1 = causal
  internal_neg = internalChosen_neg,
  internal_pos = internalChosen_pos,
  global_neg = globalChosen_neg,
  global_pos = globalChosen_pos
)

## fit model using rstan
fit <- stan(
  file = paste0("./stan-models/", model, ".stan"),
  data = data_list,
  chains = 4,               # run 4 separate chains to assess convergence
  warmup = 1000,            # these are used to tune the sampler and ’burn in’
  iter = 2000,              # number of iterations (#kept = chains*(iter - warmup))
  cores = nCores            # chains to be run in parallel on separate cores (if possible)
)

## save
saveRDS(fit, file = paste0("./stan-fits/", model ,"-", task_ver, "-fit.rds"))
# ## OR load saved model
# fit <- readRDS(file = paste0("./stan-fits/", model ,"-", task_ver, "-fit.rds"))

# summary of sampling diagnostics
check_hmc_diagnostics(fit)

# plot pairs of sampling distributions for an example participant
pairs(fit, pars=c("theta_internal_neg[1,1]", "theta_internal_neg[2,1]",
                  "theta_global_neg[1,1]",   "theta_global_neg[2,1]"))
pairs(fit, pars=c("theta_internal_pos[1,1]", "theta_internal_pos[2,1]",
                  "theta_global_pos[1,1]",   "theta_global_pos[2,1]"))

# plot pairs of sampling distributions for the group level means
pairs(fit, pars=c("mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
                  "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]"))
pairs(fit, pars=c("mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
                  "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]"))

# plot pairs of group-level intervention/learning effects (model 2 only)
pairs(fit, pars=c("theta_int_internal_neg", "theta_int_global_neg", 
                  "theta_learn_internal_neg", "theta_learn_global_neg"))
pairs(fit, pars=c("theta_int_internal_pos", "theta_int_global_pos",
                  "theta_learn_internal_pos", "theta_learn_global_pos"))
```
  
```{r int_IG_plot}
## load model
model <- "m_bernoulli_negpos_IGcorr2_multisess_intervention_learning_additive"
fit <- readRDS(file = paste0("./stan-fits/", model ,"-",  task_ver, "-fit.rds"))

# extract individual posterior parameter estimates for each session
posts <- as.data.frame(summary(fit,
                       pars = c("p_internal_pos", "p_internal_neg", 
                                "p_global_pos", "p_global_neg"))$summary) %>%
  dplyr::select(mean, sd) %>%
  add_rownames(var = "var") %>%
  separate(var, sep="\\[|\\,|\\]", into=c("parameter", "ID", "session"),
           remove=TRUE, extra="drop") %>%
  separate(parameter, sep=-3, into=c("parameter", "item_valence")) %>%
  mutate(parameter = sub("l_", "l", parameter),
         parameter = factor(parameter, levels = c("p_internal", "p_global")))

## plot
p1 <- posts %>%
  pivot_wider(id_cols=c("ID", "parameter", "item_valence"),
              names_from = "session", values_from = c("mean", "sd")) %>%
  mutate(group = ifelse(ID %in% subs_1, 1,
                        ifelse(ID %in% subs_2, 2,
                               ifelse(ID %in% subs_3, 3, NA))),
         group = as.factor(group)) %>%
  ggplot(aes(x=mean_1, y=mean_2, group=group, colour=group)) +
  geom_abline(slope = 1, linetype="dashed", colour="grey") +
  geom_point() +
  geom_errorbarh(aes(xmin = mean_1-sd_1, xmax = mean_1+sd_1), alpha=.4) +
  geom_errorbar(aes(ymin = mean_2-sd_2, ymax = mean_2+sd_2), alpha=.4) +
  geom_smooth(method = "lm", se=FALSE, formula = y ~ x) +
  scale_colour_manual(values=colours3) +
  scale_fill_manual(values=colours3) +
  labs(x = "mean (sd) time 1", y ="mean (sd) time 2") +
  theme_minimal() + facet_grid(cols=vars(item_valence), rows=vars(parameter)) + 
  theme(aspect.ratio=4/3.5)
print(p1)
# ggsave(filename = paste0("./figures/", task_ver, "-", model, "-params-by-time.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)

# plot posteriors for group-level effects of interest using tidybayes
fit_tidy <- fit %>% 
  gather_draws(`mu_internal_theta_neg[1]`, `mu_internal_theta_neg[2]`, 
               `mu_internal_theta_pos[1]`, `mu_internal_theta_pos[2]`,
               `mu_global_theta_neg[1]`,   `mu_global_theta_neg[2]`, 
               `mu_global_theta_pos[1]`,   `mu_global_theta_pos[2]`, 
               theta_int_internal_neg, theta_int_internal_pos,
               theta_int_global_neg,   theta_int_global_pos,
               theta_learn_internal_neg, theta_learn_internal_pos,
               theta_learn_global_neg,   theta_learn_global_pos) %>%
  mutate(var_type = ifelse(grepl("_int_", .variable), "intervention effect", 
                           ifelse(grepl("_learn_", .variable), "learning effect", "group mean")),
         var_type = factor(var_type, levels = c("group mean", "intervention effect", "learning effect")),
         .variable = factor(.variable, levels = c(
           "mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
           "mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
           "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]",
           "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]",
           "theta_int_internal_neg", "theta_int_internal_pos",
           "theta_int_global_neg", "theta_int_global_pos",
           "theta_learn_internal_neg", "theta_learn_internal_pos",
           "theta_learn_global_neg", "theta_learn_global_pos")))

p <- fit_tidy %>%
  ggplot(aes(y = fct_rev(.variable), x = .value, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() +
  theme(legend.position = "none") + theme(aspect.ratio=4/3) + labs(x="", y="")
p
# ggsave(filename = paste0("./figures/", task_ver, "-", model, "-choice-means-ints-CIs-gradient.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)

# print numerical values (raw / unstandardized)
params90cis <- summary(fit, pars = c(
           "mu_internal_theta_neg[1]", "mu_internal_theta_neg[2]",
           "mu_internal_theta_pos[1]", "mu_internal_theta_pos[2]",
           "mu_global_theta_neg[1]",   "mu_global_theta_neg[2]",
           "mu_global_theta_pos[1]",   "mu_global_theta_pos[2]",
           "theta_int_internal_neg", "theta_int_internal_pos",
           "theta_int_global_neg", "theta_int_global_pos",
           "theta_learn_internal_neg", "theta_learn_internal_pos",
           "theta_learn_global_neg", "theta_learn_global_pos"), probs = c(0.05, 0.95))$summary
print(params90cis)

## new plotting (standardized)
## re-transform group means to output probabilities (cf raw theta estimates which control this)
## and convert intervention effects to ~SMDs
# theta_x_int_std =theta_x_int_sd / sqrt(sigma_theta[2])
# first, get posterior (pooled) variance estimates for theta_x at time 2 (internal, global)
params90cis <- summary(fit, pars = c("pars_sigma_neg[3]",
                                     "pars_sigma_neg[4]", 
                                     "pars_sigma_pos[3]",
                                     "pars_sigma_pos[4]"), probs = c(0.05, 0.95))$summary
sigma_theta_int_neg_t2 <- params90cis[1,1]
sigma_theta_glob_neg_t2 <- params90cis[2,1]
sigma_theta_int_pos_t2 <- params90cis[3,1]
sigma_theta_glob_pos_t2 <- params90cis[4,1]

fit_tidy2 <- fit_tidy %>%
  mutate(.value2 = case_when(.variable =="mu_internal_theta_neg[1]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_neg[2]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_pos[1]" ~ inv.logit(.value),
                             .variable =="mu_internal_theta_pos[2]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_neg[1]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_neg[2]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_pos[1]" ~ inv.logit(.value),
                             .variable =="mu_global_theta_pos[2]" ~ inv.logit(.value),
                             .variable =="theta_int_internal_neg" ~ .value/sqrt(sigma_theta_int_neg_t2),
                             .variable =="theta_int_internal_pos" ~ .value/sqrt(sigma_theta_int_pos_t2),
                             .variable =="theta_int_global_neg"   ~ .value/sqrt(sigma_theta_glob_neg_t2),
                             .variable =="theta_int_global_pos"   ~ .value/sqrt(sigma_theta_glob_pos_t2),
                             .variable =="theta_learn_internal_neg" ~ .value/sqrt(sigma_theta_int_neg_t2),
                             .variable =="theta_learn_internal_pos" ~ .value/sqrt(sigma_theta_int_pos_t2),
                             .variable =="theta_learn_global_neg"   ~ .value/sqrt(sigma_theta_glob_neg_t2),
                             .variable =="theta_learn_global_pos"   ~ .value/sqrt(sigma_theta_glob_pos_t2),
                             TRUE ~ .value))
p2 <- fit_tidy2 %>%
  ggplot(aes(y = fct_rev(.variable), x = .value2, fill = var_type)) +
  stat_gradientinterval(.width = c(.9, .5),  slab_size = 1) +
  scale_fill_manual(values = colours2) +
  geom_vline(xintercept = 0, colour = "grey") + theme_minimal() +
  theme(legend.position = "none") + theme(aspect.ratio=4/3) + labs(x="", y="")
p2
# ggsave(filename = paste0("./figures/", task_ver, "-", model,
#                          "-means-ints-CIs-gradient-transf-smd.svg"),
#        plot = last_plot(), device = "svg", dpi = 300)
```

```{r mc}
## comparison between models
models_to_compare <- c("m_bernoulli_negpos_IGcorr2_multisess_intervention_additive",
                       "m_bernoulli_negpos_IGcorr2_multisess_intervention_learning_additive")
# we can use the loo_compare function to compare our two models on expected log predictive density (ELPD) for new data
for (i in 1:length(models_to_compare)) {
  fit <- readRDS(paste0("./stan-fits/",models_to_compare[i],"-",task_ver,"-fit.rds"))
  assign(paste0("loo",as.character(i)), loo(fit, mc.cores = nCores)) 
}
loo_compare(loo1, loo2) 
# in this output, the best model is defined as having zero difference to itself
# see e.g., https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html

# This is the model comparison procedure reported in (Vehtari, Gelman, &
# Gabry, 2017), which compares the expected log pointwise predictive density (ELPD) for
# each model. We determined the size of importance of ELPD difference by taking models
# greater than 5 x the SE of the estimate
```